{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab the schedule links\n",
    "ScheduleLink=[]\n",
    "for year in range(1990,2019):\n",
    "    #Get the Link and request HTML\n",
    "    Link = 'https://www.baseball-reference.com/leagues/MLB/'+str(year)+'-schedule.shtml'\n",
    "    soup = BeautifulSoup(requests.get(Link).text, \"html.parser\")\n",
    "    Sch = soup.find_all(\"div\", \"section_wrapper\")\n",
    "    \n",
    "    #Get the Season links.\n",
    "    SeasonLinks=Sch[0].find_all('a')\n",
    "    BoxscoreLinksSeason = [x.get('href') for x in SeasonLinks if x.get_text()=='Boxscore']\n",
    "    \n",
    "    #Append the links.\n",
    "    if year < 2018:\n",
    "        PostSeasonLinks=Sch[1].find_all('a')\n",
    "        BoxscoreLinksPostSeason = [x.get('href') for x in PostSeasonLinks if x.get_text()=='Boxscore']\n",
    "        ScheduleLink = ScheduleLink+BoxscoreLinksSeason+BoxscoreLinksPostSeason\n",
    "    else:\n",
    "        ScheduleLink = ScheduleLink+BoxscoreLinksSeason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the schedule page\n",
    "WeatherData = []\n",
    "for link in ScheduleLink:\n",
    "    Link = 'https://www.baseball-reference.com'+link\n",
    "    soup = BeautifulSoup(requests.get(Link).text, \"html.parser\")\n",
    "\n",
    "    #Date HomeTeam AwayTeam GameTime Temperature\n",
    "\n",
    "    #Date\n",
    "    shortDate=ScheduleLink[0].split('/')[3].split('.')[0][3:]\n",
    "    Date = shortDate[:4]+'-'+shortDate[4:6]+'-'+shortDate[6:8]\n",
    "\n",
    "    #Clean stupid links\n",
    "    stupidLinks = soup.find_all(\"div\", \"linescore_wrap\")[0].find_all('tbody')[0].find_all('a')\n",
    "    Links = [x for x in stupidLinks if \"teams\" in x.get('href')]\n",
    "\n",
    "    #Teams\n",
    "    AwayTeam = Links[0].get_text()\n",
    "    HomeTeam = Links[1].get_text()\n",
    "\n",
    "    #Weather\n",
    "    try:\n",
    "        strings = str(soup.find_all('body', 'br')[0].find_all('div','section_wrapper',id='all_6309354931')[0])\n",
    "        Weather=strings.split('<div>')[-1].split(\"</strong>\")[1].split('<')[0].strip()\n",
    "\n",
    "        if Weather == 'In Dome.':\n",
    "            Temp = 73.4\n",
    "        else:\n",
    "            try:\n",
    "                Temp = float(Weather.split('&')[0])\n",
    "            except:\n",
    "                Temp = 'NA'\n",
    "    except:\n",
    "        Temp = 'NA'\n",
    "\n",
    "    Row = [Date, HomeTeam, AwayTeam, Temp]\n",
    "    WeatherData.append(Row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeatherData = pd.DataFrame(data=WeatherData, columns=['Date', 'Home Team', 'Away Team', 'Temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeatherData.to_csv('./Schedules/TempData/HistoricalWeather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
